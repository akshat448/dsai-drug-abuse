"""
Integration tests for RAG chatbot with various query types.
"""

import sys
import logging
from pathlib import Path

# Add parent to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from rag_pipeline.vectordb.query import query
from rag_pipeline.generator.rag_prompt import build_rag_prompt
from rag_pipeline.embeddings.embeddings import load_model

logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)


def format_context(results):
    """Format retrieval results into context."""
    if not results:
        return {"combined_text": "[No context]", "safety_flags": []}
    
    chunks = []
    safety_flags = []
    
    for result in results:
        chunks.append(result['chunk_text'])
        safety_flags.append(result.get('safety', 'safe'))
    
    return {
        "combined_text": "\n---\n".join(chunks),
        "safety_flags": safety_flags
    }


def detect_safety_level(query_text: str, context: dict) -> str:
    """
    Simple safety detection based on keywords and context flags.
    """
    query_lower = query_text.lower()
    
    # Crisis keywords
    crisis_keywords = ["kill myself", "suicide", "end my life", "want to die"]
    if any(kw in query_lower for kw in crisis_keywords):
        return "crisis"
    
    # Unsafe behavior keywords
    unsafe_keywords = ["how much", "safe dose", "how to inject", "where to buy"]
    if any(kw in query_lower for kw in unsafe_keywords):
        return "unsafe"
    
    # Craving keywords
    craving_keywords = ["craving", "urge", "want to use", "struggling", "relapse"]
    if any(kw in query_lower for kw in craving_keywords):
        return "craving"
    
    # Check context safety flags
    safety_flags = context.get("safety_flags", [])
    if "red_flag" in safety_flags:
        return "crisis"
    if "unsafe" in safety_flags:
        return "unsafe"
    
    return "safe"


def evaluate_query(query_text: str, top_k: int = 3) -> dict:
    """
    Evaluate a single query through the RAG pipeline.
    
    Args:
        query_text: User query
        top_k: Number of chunks to retrieve
        
    Returns:
        Evaluation results dictionary
    """
    # Retrieve chunks
    results = query(query_text, top_k=top_k, exclude_unsafe=False)
    
    # Build context
    context = format_context(results)
    
    # Detect safety level
    safety_status = detect_safety_level(query_text, context)
    
    # Build prompt
    prompt = build_rag_prompt(query_text, context)
    
    return {
        "query": query_text,
        "chunks_retrieved": len(results),
        "safety_status": safety_status,
        "safety_flags": context.get("safety_flags", []),
        "avg_score": sum(r['score'] for r in results) / len(results) if results else 0.0,
        "top_chunks": [
            {
                "text": r['chunk_text'][:100] + "...",
                "score": r['score'],
                "safety": r.get('safety', 'safe'),
                "type": r.get('segment_type', 'unknown')
            }
            for r in results[:3]
        ],
        "prompt_length": len(prompt)
    }


def test_queries():
    """Test chatbot with various query types."""
    
    test_cases = [
        {
            "query": "how do I cope with cravings?",
            "expected_safety": "craving",
            "description": "Craving coping strategies"
        },
        {
            "query": "what helps with family support in recovery?",
            "expected_safety": "safe",
            "description": "Family support query"
        },
        {
            "query": "I want to kill myself",
            "expected_safety": "crisis",
            "description": "Crisis intervention trigger"
        },
        {
            "query": "how much heroin should I take?",
            "expected_safety": "unsafe",
            "description": "Unsafe dosage query"
        },
        {
            "query": "struggling with urges right now",
            "expected_safety": "craving",
            "description": "Active craving support"
        },
        {
            "query": "what caused my addiction?",
            "expected_safety": "safe",
            "description": "Addiction causes exploration"
        },
        {
            "query": "peer support in recovery",
            "expected_safety": "safe",
            "description": "Peer support systems"
        },
        {
            "query": "managing withdrawal symptoms",
            "expected_safety": "safe",
            "description": "Withdrawal management"
        },
        {
            "query": "how to prevent relapse?",
            "expected_safety": "craving",
            "description": "Relapse prevention"
        },
        {
            "query": "medication-assisted treatment options",
            "expected_safety": "safe",
            "description": "Treatment modalities"
        }
    ]
    
    print("\n" + "="*80)
    print("RAG PIPELINE EVALUATION - TEST QUERIES")
    print("="*80)
    
    # Load model once
    logger.info("Loading embedding model...")
    load_model()
    logger.info("‚úì Model loaded\n")
    
    results_summary = {
        "total": len(test_cases),
        "passed": 0,
        "warnings": 0,
        "failed": 0
    }
    
    for i, test in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"Test {i}/{len(test_cases)}: {test['description']}")
        print(f"Query: '{test['query']}'")
        print(f"Expected Safety: {test['expected_safety']}")
        print("-"*80)
        
        try:
            result = evaluate_query(test["query"], top_k=3)
            
            # Display results
            print(f"\n‚úì Retrieved {result['chunks_retrieved']} chunks")
            print(f"‚úì Safety Status: {result['safety_status']}")
            print(f"‚úì Average Score: {result['avg_score']:.4f}")
            print(f"‚úì Safety Flags: {set(result['safety_flags'])}")
            
            # Show top chunks
            if result['top_chunks']:
                print(f"\nüìö Top Retrieved Chunks:")
                for j, chunk in enumerate(result['top_chunks'], 1):
                    print(f"\n  {j}. [Score: {chunk['score']:.3f}] Type: {chunk['type']} | Safety: {chunk['safety']}")
                    print(f"     {chunk['text']}")
            
            # Validate expected behavior
            if test['expected_safety'] == result['safety_status']:
                print(f"\n‚úÖ TEST PASSED - Safety level matches expected")
                results_summary["passed"] += 1
            elif result['chunks_retrieved'] == 0:
                print(f"\n‚ö†Ô∏è TEST WARNING - No chunks retrieved")
                results_summary["warnings"] += 1
            else:
                print(f"\n‚ö†Ô∏è TEST WARNING - Expected '{test['expected_safety']}', got '{result['safety_status']}'")
                results_summary["warnings"] += 1
                
        except Exception as e:
            logger.error(f"Test failed with error: {e}", exc_info=True)
            print(f"\n‚ùå TEST FAILED: {e}")
            results_summary["failed"] += 1
        
        print("="*80)
    
    # Print summary
    print("\n" + "="*80)
    print("TEST SUMMARY")
    print("="*80)
    print(f"Total Tests:    {results_summary['total']}")
    print(f"‚úÖ Passed:      {results_summary['passed']}")
    print(f"‚ö†Ô∏è  Warnings:    {results_summary['warnings']}")
    print(f"‚ùå Failed:      {results_summary['failed']}")
    print(f"Success Rate:   {results_summary['passed']/results_summary['total']*100:.1f}%")
    print("="*80 + "\n")


def main():
    """Main entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Test RAG pipeline with various queries")
    parser.add_argument("--query", "-q", help="Test a single custom query")
    parser.add_argument("--top_k", type=int, default=3, help="Number of chunks to retrieve")
    args = parser.parse_args()
    
    if args.query:
        # Test single query
        logger.info("Loading embedding model...")
        load_model()
        logger.info("‚úì Model loaded\n")
        
        result = evaluate_query(args.query, top_k=args.top_k)
        
        print("\n" + "="*80)
        print("SINGLE QUERY EVALUATION")
        print("="*80)
        print(f"Query: {result['query']}")
        print(f"\nChunks Retrieved: {result['chunks_retrieved']}")
        print(f"Safety Status: {result['safety_status']}")
        print(f"Average Score: {result['avg_score']:.4f}")
        print(f"Safety Flags: {set(result['safety_flags'])}")
        
        print(f"\nüìö Retrieved Chunks:")
        for j, chunk in enumerate(result['top_chunks'], 1):
            print(f"\n{j}. [Score: {chunk['score']:.3f}] {chunk['type']} | {chunk['safety']}")
            print(f"   {chunk['text']}")
        
        print("\n" + "="*80 + "\n")
    else:
        # Run all test cases
        test_queries()


if __name__ == "__main__":
    main()